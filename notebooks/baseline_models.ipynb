{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# cross validation\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "# classification report\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "# baseline models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# classification report\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Dataset/Tweets.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing code from exploration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ....\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to ....\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to ....\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports for preprocessing\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download(['stopwords', 'wordnet', 'omw-1.4'], download_dir='.')\n",
    "# print('before:', nltk.data.path)\n",
    "if '.' not in nltk.data.path:\n",
    "    nltk.data.path.append('.')\n",
    "# print('after:', nltk.data.path)\n",
    "\n",
    "# preprocessing text\n",
    "import regex as re\n",
    "\n",
    "\n",
    "# drop unneeded columns\n",
    "dataset.drop(['textID', 'selected_text'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# don't remove some stop words that might make a difference in positive/negative classification\n",
    "stop_words_keep = {'against', 'before', 'after', 'up', 'down', 'in', 'out', 'on', 'off', \n",
    "                    'no', 'nor', 'not', 'only', 'don\\'t', 'aren\\'t', 'couldn\\'t', 'didn\\'t', \n",
    "                    'doesn\\'t', 'hadn\\'t', 'hasn\\'t', 'isn\\'t', 'mightn\\'t', 'mustn\\'t', \n",
    "                    'needn\\'t', 'shan\\'t', 'shouldn\\'t', 'wasn\\'t', 'weren\\'t', 'won\\'t', \n",
    "                    'wouldn\\'t'}\n",
    "\n",
    "sw = stopwords.words(\"english\")\n",
    "stop_words = [w for w in sw if w not in stop_words_keep]\n",
    "\n",
    "\n",
    "# preprocessing function\n",
    "\n",
    "def preprocess(text, remove_apos_backtick=True, lemmatize=True, stem=True, rem_len_1=True, rem_stop_words=True):\n",
    "    \n",
    "    # create lemmatizer and stemmer.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    # regex patterns.\n",
    "    url_pattern         = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    user_pattern        = '@[^\\s]+'\n",
    "    alpha_pattern       = \"[^a-zA-Z0-9`\\']\" # keep back ticks (` used instead of ' in the dataset) and apostrophes (')\n",
    "    sequence_pattern    = r\"(.)\\1\\1+\"\n",
    "    seq_replace_pattern = r\"\\1\\1\"\n",
    "    \n",
    "    # lowercasing\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # replace apostrophes and backticks with empty string\n",
    "    if remove_apos_backtick:\n",
    "        text = re.sub('[\\'`]', '', text)\n",
    "\n",
    "    # replace all URls with 'URL'\n",
    "    text = re.sub(url_pattern, ' URL ',text)\n",
    "         \n",
    "    # replace @USERNAME to 'USER'.\n",
    "    text = re.sub(user_pattern, ' USER ', text)        \n",
    "\n",
    "    # replace all non letters, non numbers (except backticks and apostrophes)\n",
    "    text = re.sub(alpha_pattern, ' ', text)\n",
    "\n",
    "    # replace 3 or more consecutive characters by 2 of that character\n",
    "    text = re.sub(sequence_pattern, seq_replace_pattern, text)\n",
    "\n",
    "    preproc_text = ''\n",
    "\n",
    "    # for each word in text\n",
    "    for word in text.split():\n",
    "        \n",
    "        # ignore words of length 1\n",
    "        if len(word) > 1 or not rem_len_1:\n",
    "\n",
    "            # lemmatize\n",
    "            if lemmatize:\n",
    "                word = lemmatizer.lemmatize(word)\n",
    "\n",
    "            # check if stopword\n",
    "            if word not in stop_words or not rem_stop_words:\n",
    "\n",
    "                # stem \n",
    "                if stem:\n",
    "                    word = stemmer.stem(word)\n",
    "                    \n",
    "                preproc_text += (word + ' ')\n",
    "        \n",
    "    return preproc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing to dataset \n",
    "\n",
    "dataset['text'] = dataset['text'].apply(lambda t: preprocess(t, stem=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply bag-of-words and TF-IDF to generate new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "# remember, don't peek at (evaluate on) the test set!\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop(['sentiment'], axis='columns'), dataset['sentiment'], test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data text feature into new features using bag of words, tf-idf\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# represent examples as the counts for each word they contain\n",
    "bag_of_words = count_vectorizer.fit_transform(X_train['text'])\n",
    "\n",
    "# represent examples as the tf-idf score for each word they contain\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(X_train['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation and classification reports for baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up for k-fold cross validation and metric gathering\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision_neut' : make_scorer(precision_score, average=None, labels=['neutral']),\n",
    "           'precision_pos'  : make_scorer(precision_score, average=None, labels=['positive']),\n",
    "           'precision_neg'  : make_scorer(precision_score, average=None, labels=['negative']),\n",
    "           'recall_neut'    : make_scorer(recall_score,    average=None, labels=['neutral']), \n",
    "           'recall_pos'     : make_scorer(recall_score,    average=None, labels=['positive']), \n",
    "           'recall_neg'     : make_scorer(recall_score,    average=None, labels=['negative']), \n",
    "           'f1_score_neut'  : make_scorer(f1_score,        average=None, labels=['neutral']),\n",
    "           'f1_score_pos'   : make_scorer(f1_score,        average=None, labels=['positive']),\n",
    "           'f1_score_neg'   : make_scorer(f1_score,        average=None, labels=['negative'])}\n",
    "\n",
    "k_fold = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print out a classification report\n",
    "# can't use normal classification_report since we want to display our values from cross validation\n",
    "def custom_classif_report(metric_scores, just_acc=False):\n",
    "\n",
    "  scores_df = pd.DataFrame(metric_scores)\n",
    "  \n",
    "  # average of each metric over the splits of cross validation\n",
    "  scores_mean = scores_df.mean() \n",
    "  \n",
    "  # overall averages for precision, recall, and f1 across class labels\n",
    "  avg_precision = scores_mean[['test_precision_neut', 'test_precision_pos', 'test_precision_neg']].mean()\n",
    "  avg_recall = scores_mean[['test_recall_neut', 'test_recall_pos', 'test_recall_neg']].mean()\n",
    "  avg_f1 = scores_mean[['test_f1_score_neut', 'test_f1_score_pos', 'test_f1_score_neg']].mean()\n",
    "  \n",
    "  print('Classification Report:')\n",
    "\n",
    "  # precision, recall, f1 metrics in table printable form\n",
    "  metric_info = {\n",
    "    'precision': [scores_mean['test_precision_neut'], scores_mean['test_precision_pos'], scores_mean['test_precision_neg'], avg_precision], \n",
    "    'recall': [scores_mean['test_recall_neut'], scores_mean['test_recall_pos'], scores_mean['test_recall_neg'], avg_recall], \n",
    "    'f1-score': [scores_mean['test_f1_score_neut'], scores_mean['test_f1_score_pos'], scores_mean['test_f1_score_neg'], avg_f1]}\n",
    "  \n",
    "  # print table for precision, recall, f1\n",
    "  if not just_acc:\n",
    "    print(tabulate(metric_info, headers='keys', tablefmt='fancy_grid', showindex=['neutral', 'positive', 'negative', 'average']))\n",
    "  \n",
    "  # print table for accuracy\n",
    "  acc_info = {'accuracy': [scores_mean['test_accuracy']]}\n",
    "  print(tabulate(acc_info, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes with bag of words features Classification Report:\n",
      "╒══════════╤═════════════╤══════════╤════════════╕\n",
      "│          │   precision │   recall │   f1-score │\n",
      "╞══════════╪═════════════╪══════════╪════════════╡\n",
      "│ neutral  │    0.601459 │ 0.665177 │   0.631585 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ positive │    0.716753 │ 0.688228 │   0.702009 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ negative │    0.673007 │ 0.599565 │   0.634062 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ average  │    0.66374  │ 0.65099  │   0.655885 │\n",
      "╘══════════╧═════════════╧══════════╧════════════╛\n",
      "╒════════════╕\n",
      "│   accuracy │\n",
      "╞════════════╡\n",
      "│   0.654021 │\n",
      "╘════════════╛\n",
      "\n",
      "Naive bayes with tf-idf features Classification Report:\n",
      "╒══════════╤═════════════╤══════════╤════════════╕\n",
      "│          │   precision │   recall │   f1-score │\n",
      "╞══════════╪═════════════╪══════════╪════════════╡\n",
      "│ neutral  │    0.537034 │ 0.824773 │   0.650333 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ positive │    0.764198 │ 0.563785 │   0.648615 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ negative │    0.769019 │ 0.398299 │   0.524443 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ average  │    0.690084 │ 0.595619 │   0.607797 │\n",
      "╘══════════╧═════════════╧══════════╧════════════╛\n",
      "╒════════════╕\n",
      "│   accuracy │\n",
      "╞════════════╡\n",
      "│   0.623136 │\n",
      "╘════════════╛\n"
     ]
    }
   ],
   "source": [
    "mnb_model = MultinomialNB() \n",
    "\n",
    "print('Naive bayes with bag of words features ', end='')\n",
    "scores = cross_validate(mnb_model, bag_of_words, y_train, cv=k_fold, scoring=scoring)\n",
    "custom_classif_report(scores)\n",
    "\n",
    "print('\\nNaive bayes with tf-idf features ', end='')\n",
    "scores = cross_validate(mnb_model, tfidf_features, y_train, cv=k_fold, scoring=scoring)\n",
    "custom_classif_report(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM with bag of words features Classification Report:\n",
      "╒══════════╤═════════════╤══════════╤════════════╕\n",
      "│          │   precision │   recall │   f1-score │\n",
      "╞══════════╪═════════════╪══════════╪════════════╡\n",
      "│ neutral  │    0.631889 │ 0.658896 │   0.644897 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ positive │    0.723534 │ 0.71502  │   0.719116 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ negative │    0.659781 │ 0.627325 │   0.642941 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ average  │    0.671735 │ 0.66708  │   0.668985 │\n",
      "╘══════════╧═════════════╧══════════╧════════════╛\n",
      "╒════════════╕\n",
      "│   accuracy │\n",
      "╞════════════╡\n",
      "│    0.66753 │\n",
      "╘════════════╛\n",
      "\n",
      "Linear SVM with tf-idf features Classification Report:\n",
      "╒══════════╤═════════════╤══════════╤════════════╕\n",
      "│          │   precision │   recall │   f1-score │\n",
      "╞══════════╪═════════════╪══════════╪════════════╡\n",
      "│ neutral  │    0.628901 │ 0.697245 │   0.661162 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ positive │    0.748549 │ 0.706679 │   0.726936 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ negative │    0.687424 │ 0.622207 │   0.653017 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ average  │    0.688291 │ 0.675377 │   0.680372 │\n",
      "╘══════════╧═════════════╧══════════╧════════════╛\n",
      "╒════════════╕\n",
      "│   accuracy │\n",
      "╞════════════╡\n",
      "│   0.679038 │\n",
      "╘════════════╛\n"
     ]
    }
   ],
   "source": [
    "linear_svm_model = LinearSVC(max_iter=10000)\n",
    "\n",
    "print('Linear SVM with bag of words features ', end='')\n",
    "scores = cross_validate(linear_svm_model, bag_of_words, y_train, cv=k_fold, scoring=scoring)\n",
    "custom_classif_report(scores)\n",
    "\n",
    "print('\\nLinear SVM with tf-idf features ', end='')\n",
    "scores = cross_validate(linear_svm_model, tfidf_features, y_train, cv=k_fold, scoring=scoring)\n",
    "custom_classif_report(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regresssion with bag of words features Classification Report:\n",
      "╒══════════╤═════════════╤══════════╤════════════╕\n",
      "│          │   precision │   recall │   f1-score │\n",
      "╞══════════╪═════════════╪══════════╪════════════╡\n",
      "│ neutral  │    0.643139 │ 0.726928 │   0.682219 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ positive │    0.771864 │ 0.722245 │   0.746064 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ negative │    0.706829 │ 0.624201 │   0.662644 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ average  │    0.707277 │ 0.691125 │   0.696976 │\n",
      "╘══════════╧═════════════╧══════════╧════════════╛\n",
      "╒════════════╕\n",
      "│   accuracy │\n",
      "╞════════════╡\n",
      "│   0.696507 │\n",
      "╘════════════╛\n",
      "\n",
      "Logistic regresssion with tf-idf features Classification Report:\n",
      "╒══════════╤═════════════╤══════════╤════════════╕\n",
      "│          │   precision │   recall │   f1-score │\n",
      "╞══════════╪═════════════╪══════════╪════════════╡\n",
      "│ neutral  │    0.621557 │ 0.773725 │   0.689164 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ positive │    0.791494 │ 0.686613 │   0.735129 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ negative │    0.737845 │ 0.585547 │   0.652733 │\n",
      "├──────────┼─────────────┼──────────┼────────────┤\n",
      "│ average  │    0.716966 │ 0.681961 │   0.692342 │\n",
      "╘══════════╧═════════════╧══════════╧════════════╛\n",
      "╒════════════╕\n",
      "│   accuracy │\n",
      "╞════════════╡\n",
      "│   0.693504 │\n",
      "╘════════════╛\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "print('Logistic regresssion with bag of words features ', end='')\n",
    "scores = cross_validate(logreg_model, bag_of_words, y_train, cv=k_fold, scoring=scoring)\n",
    "custom_classif_report(scores)\n",
    "\n",
    "print('\\nLogistic regresssion with tf-idf features ', end='')\n",
    "scores = cross_validate(logreg_model, tfidf_features, y_train, cv=k_fold, scoring=scoring)\n",
    "custom_classif_report(scores)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3a5ec43c2134eab692cc945203422f050c3bda7e5881ff7e11f810cfd5e42c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ECS171_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
